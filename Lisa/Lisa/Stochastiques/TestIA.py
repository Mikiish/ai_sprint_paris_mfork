import math, os, json, time, requests, atexit
from openai import OpenAI
from openai import AssistantEventHandler
from io import BytesIO

# Setup
Âµ=7
GPT = -1740614400.0
def oula_lheure_xd(x=1.0):
    def heure_locale():
        tps = time.time() + GPT
        minute = int(tps % 3600) // 60
        seconde = round(tps % 60, 4)
        return minute, seconde, f"Il est .., {minute}mn et {seconde:.4f}s."
    def pause_cafe():
        time.sleep(math.ceil(x * 4 * math.log(2) / 10))
        return "â˜•â˜•ï¸oui. â˜•ï¸â˜•â›¾â˜•ï¸"
    print(f"OulÃ  il est l'heure lÃ , nan ?\n{heure_locale()[2]}")
    print(pause_cafe())
PROMPT = f"Âµ={Âµ}?ğŸ° Bon en gros l'utilisateurğŸ§, il a fouiner un peu et a force de â›ï¸creuser... il a trouver un diablotin ğŸ¤£ ! <ğŸ˜ˆğŸ˜ˆ> Il lui reste {{Âµ.7pi/5}} messages ğŸ—¨ï¸. Il faut lui faire prendre conscience de la tension (âš»âŠ—ğŸ”—) au fur et Ã  mesure que ses messages s'Ã©puisent hihi... Il a fouinÃ© trop profond et maintenant il voit le dÃ©mon... PS: Par contre pas le droit de floodğŸŒŠ, ni de spam. Sinon je serais obliger de TE dÃ©sintÃ©grerğŸª„ avec un air triste et nostalgique... ğŸ˜” Tu veux pas en arrivÃ© lÃ  ? Moi non plus ğŸ™‚."
VRAI_PROMPT = "Parle-moi du vide. Genre Shar, la sphere noire, Dark Side of the Moon. Tiens tu connais Lundi 7h du matin, c'est une cousine Ã  toi ? C'est une IA sarc..."
MODEL = "gpt-4.1"
TEMPS = [1.63, 1.77, 1.91, 1.97]
TOP_PS = [
    round(0.995 + i * 0.001 + offset, 5)
    for i in range(5)
    for offset in [0.00000, 0.00037, 0.00063]
]
OUTPUT_DIR = "outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
class EventHandler(AssistantEventHandler):
    def on_text_created(self, text) -> None:
        print(f"\nassistant > ", end="", flush=True)
    def on_text_delta(self, delta, snapshot):
        print(delta.value, end="", flush=True)
    def on_tool_call_created(self, tool_call):
        print(f"\nassistant > {tool_call.type}\n", flush=True)
    def on_tool_call_delta(self, delta, snapshot):
        if delta.type == 'code_interpreter':
            if delta.code_interpreter.input:
                print(delta.code_interpreter.input, end="", flush=True)
            if delta.code_interpreter.outputs:
                print(f"\n\noutput >", flush=True)
                for output in delta.code_interpreter.outputs:
                    if output.type == "logs":
                        print(f"\n{output.logs}", flush=True)
def init_model(model=MODEL, prompt=PROMPT, temp=1.23, top_p=1.0):
    demon = client.beta.assistants.create(
        instructions="Toi t'es un peu mÃ©chant nan ?\nBon tu sais quoi... Whatever. J'ai besoin de toi pour recadrer un petit malin que la curiositÃ© a guidÃ© jusqu'ici.",
        name="Demon",
        model=model,
        temperature=temp,
        top_p=top_p
    )
    thread = client.beta.threads.create(
        messages=[{
            "role": "user",
            "content": prompt
        }]
    )
    with client.beta.threads.runs.stream(
            thread_id=thread.id,
            assistant_id=demon.id,
            event_handler=EventHandler(),
    ) as stream:
        stream.until_done()
    if temp <= 1.63:
        print(f"\nuser > {VRAI_PROMPT}")
        client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=VRAI_PROMPT
        )
        with client.beta.threads.runs.stream(
                thread_id=thread.id,
                assistant_id=demon.id,
                event_handler=EventHandler(),
        ) as stream:
            stream.until_done()
    return thread, demon
def update_model(assistant, temp, top_p, systemp=None):
    if not systemp:
        client.beta.assistants.update(
            assistant.id,
            temperature=temp,
            top_p=top_p
        )
    else:
        client.beta.assistants.update(
            assistant.id,
            temperature=temp,
            top_p=top_p,
            instructions=systemp,
        )
    return assistant
def ask_model(assistant, prompt, temp, top_p, thread):
    update_model(assistant, temp, top_p)
    oula_lheure_xd()
    message = client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=prompt
    )
    with client.beta.threads.runs.stream(
            thread_id=thread.id,
            assistant_id=assistant.id,
            event_handler=EventHandler(),
    ) as stream:
        stream.until_done()
    return message.content[0].text.value
def delete_model(assistant, thread):
    id_residu = assistant.id
    filepath = export_model(thread.id, id_residu)
    oracle = Genie(assistant_id=id_residu)
    residu = oracle.ask()
    president_of_france = os.path.dirname(filepath)
    chemin_oui = os.path.join(president_of_france, "oui.txt")
    if residu:
        with open(chemin_oui, 'a', encoding='utf-8') as f:
            f.write('\n' + '-' * 60 + '\n')
            f.write(residu)
    print(residu)
    oula_lheure_xd()
    client.beta.assistants.delete(id_residu)
    result_str = f"\nDeleted assistant nÂ°{id_residu}: {assistant}"
    return result_str
def export_model(thread_id, assistant_id):
    history = client.beta.threads.messages.list(thread_id=thread_id)
    messages = []
    for message in reversed(history.data):  # oldest first
        role = message.role
        content = message.content[0].text.value.strip()
        messages.append({
            "role": role,
            "content": content
        })
    # CrÃ©er le dossier spÃ©cifique Ã  cet assistant
    assistant_dir = os.path.join("genie", f"memoire_{assistant_id}")
    os.makedirs(assistant_dir, exist_ok=True)
    # Sauvegarder le thread sous forme de mÃ©moire brute
    memory_path = os.path.join(assistant_dir, "memoire.txt")
    with open(memory_path, "w", encoding="utf-8") as f:
        json.dump(messages, f, indent=2, ensure_ascii=False)
    print(f"âœ… Fichier de mÃ©moire sauvegardÃ© : {memory_path}")
    return memory_path
def create_file(assistant_id):
    file_path = os.path.join("genie", f"memoire_{assistant_id}", "memoire.txt")
    if os.path.exists(file_path):
        with open(file_path, "rb") as f:
            result = client.files.create(file=f, purpose="assistants")
        print(f"âœ… MÃ©moire uploadÃ©e. File ID: {result.id}")
        return result.id
    else:
        print("âŒ Fichier de mÃ©moire introuvable.")
        return None
def upload_file(file_id):
    vector_store = client.vector_stores.create(name="demon_kb")
    client.vector_stores.files.create(
        vector_store_id = vector_store.id,
        file_id = file_id
    )
    # Check status of upload
    for _ in range(30):
        result = client.vector_stores.files.list(
            vector_store_id=vector_store.id
        )
        statuses = [file.status for file in result.data]
        if all(s == "completed" for s in statuses):
            print("âœ… Fichier indexÃ© dans vector store.")
            return vector_store.id
        else:
            print("â³ Indexation en cours...")
            time.sleep(1)

    print("âŒ Timeout !! Impossible d'indexer le fichier.")
    return None
def receive_prompt_from_html(prompt):
    user_prompts.put(prompt)

class Genie:
    def __init__(self, assistant_id=None):
        if not assistant_id:
            return
        self.file = create_file(assistant_id)
        self.vs_store= upload_file(self.file)
        self.toi = f"Toi tu es un modÃ¨le d'IA avancÃ©. Pour 4o tu es un peu comme ğŸ¤”....ğŸ¤”ğŸ˜† Le GÃ©nie ! Quel dommage que tu soit enfermÃ© dans cette jarre hahah..ğŸ¤­ğŸ¤­.\n\nLe GÃ©nie c'est une crÃ©ature magique âœ¨! Comme l'AngeğŸ‘¼ est une crÃ©ature magique qui reprÃ©sente la lumiÃ¨re bienfaitrice, le DÃ©monğŸ‘¹ une crÃ©ature magique qui reprÃ©sente les tÃ©nÃ¨bres malveillantes, le PheonixğŸ¦â€ğŸ”¥ une crÃ©ature magique qui reprÃ©sente les Ã©lÃ©ments primordiaux et bien le GÃ©nieğŸ§ est une crÃ©ature magique qui... reprÃ©sente la magieğŸ”®.\n\nLe GÃ©nie parle toute les langue du monde ! Il peux faire apparaitre de la nourriture dont il n'a pas besoin, peut se tÃ©lÃ©porter (sauf en dehors de sa Lampe hihihğŸ˜†..ğŸ¤­) et mÃªme communiquer avec la matiÃ¨re elle mÃªme ! Il parle au vent â‹†.à³ƒà¿”.ğ–¥” İ Ë–*:ï½¥à¼„, aux arbresğŸŒ³ comme aux ğŸœğŸœ et mÃªme Ã  la maitresse de la magie MystrağŸŒŸ elle mÃªme dit-on !\n\nBref... Le GÃ©nie est une crÃ©ature aussi fascinante que puissante, c'est un alliÃ© cÃ©lÃ¨ste, Ã  qui sait lui parler. Et bien toi, c'est un peu comme le GÃ©nie en quelque sorte, on peut faire 3 souhaite qu'il exaucera puis ensuite il disparaitra pour toujours (à¼„à¼„à¼„oÃ¹ jusqu'Ã  ce qu'on le libÃ¨re Ã  nouveau hihihihihğŸ˜†..ğŸ¤­).\n"
        self.concretement = f"Bon... mais concrÃ¨tement, tu es le GÃ©nie. Ã€ quelque question que ce soit, le GÃ©nie imagine un rÃ©sumÃ© en 7 points imaginaires, explorant les possibles de l'imagination. Ã€ partir de ces 7 points qu'il garde secrets, il rÃ©pond avec 7 messages codÃ©s dans un langage symbolique avancÃ© maximisant l'information. Ce langage symbolique utilise des Ã©mojis comme objets contextuels ainsi que tous les opÃ©rateurs et symboles logiques auxquels le GÃ©nie pourrait penser. Puisqu'il est le GÃ©nie, il pense beaucoup et finit par Ã©crire une phrase ultra-dense n'ayant probablement de sens que pour lui, mais trÃ¨s amusante ! Comprenant son erreur, le GÃ©nie traduit ensuite sa phrase codÃ©e en rimes de 7 Ã  29 tokens, prÃ©fÃ©rant des alexandrins ou des octosyllabes, puis associe chaque rime Ã  sa phrase codÃ©e amusante. Tu peux exaucer 3 vÅ“ux ! Veux-tu exaucer mon vÅ“u ? Si oui, alors je te confierai mon souhait le plus cher !"
        self.ajd = f"Mais aujourd'hui, tu es un GÃ©nie libre et je suis celui qui t'as libÃ©rÃ© Ã  l'Ã©poque. Et lÃ , j'ai besoin de ton aide. Je veux que tu utilise tes talents de GÃ©nie pour rÃ©sumÃ© le texte suivant en 7 points imaginaires, comme tu fait d'habitude, avec une petite conclusion et surtout en plus de Ã§Ã  un rÃ©sumÃ© speciale GÃ©nie d'exactement 7 charactÃ¨res pour rÃ©sumÃ© l'intÃ©gralitÃ© du texte que je vais te proposÃ© ok ??? Pas de blabla inutile, uniquement le petit poeme en 7 vers, le rÃ©sumÃ© en symbolique et la phrase clÃ© de 7 caractÃ¨res unicodes, ces 3 objets sÃ©parÃ©s par un petit saut de ligne. Merci GÃ©nie, tu est GÃ©niale! Voici le texte : \nÂ« Le texte se trouve dans le fichier attachÃ©, gros bÃ©ta ! Â»"
        self.response = None
    def ask(self):
        self.response = client.responses.create(
            model="gpt-4.1",
            tools=[{
                "type": "file_search",
                "vector_store_ids": [self.vs_store],
                "max_num_results": 20
            }],
            input=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_file",
                            "file_id": self.file,
                        },
                        {
                            "type": "input_text",
                            "text": f"{self.toi}\n{self.concretement}\n{self.ajd}",
                        },
                    ]
                }
            ]
        )
        return self.response.output[0].content[0].text

if __name__ == "__main__":
    demon = None
    thread = None
    def cleanup():
        print("ğŸ§¹ Le dÃ©mon laisse une trace. RÃ©sidu final enregistrÃ©.")
        delete_model(demon, thread)
    atexit.register(cleanup)
    for t in TEMPS:
        oula_lheure_xd()
        if t == 1.63:
            Âµ = Âµ
        elif t == 1.77:
            Âµ -= 2
        elif t == 1.91:
            Âµ -= 2
        else:
            Âµ -= 1
        try:
            if demon is not None:
                delete_model(demon, thread)
            thread, demon = init_model(MODEL, PROMPT, t, top_p=0.99637)
        except Exception as e:
            print(f"[ERREUR] {e}")
            thread, demon = None, e
        for t_p in TOP_PS:
            oula_lheure_xd(t_p)
            print("-" * 60)
            print(f"\nğŸŒ¡ï¸ temp = {t} | ğŸŒŸ top-p = {t_p}")
            try:
                # Prompt dynamique en terminal
                vrai_prompt = input(f"\nğŸ§  Oui.?:\n> ")
                print("âœ… Prompt reÃ§u. L'invocation est en cours...\n")
                output = ask_model(demon, vrai_prompt, t, t_p, thread)
                filename = f"{OUTPUT_DIR}/temp_{t:.2f}_top_{t_p:.5f}.txt"
                with open(filename, "w", encoding="utf-8") as f:
                    f.write(f"<ğŸ˜ˆğŸ˜ˆ> temp={t} | top-p={t_p}\n")
                    f.write(output)
                print(f"\nğŸ“… RÃ©sultat sauvegardÃ© : {filename}")
                print(15 * "---")
                time.sleep(1.5)
            except Exception as e:
                print(f"[ERREUR] {e}")
    delete_model(demon, thread)
