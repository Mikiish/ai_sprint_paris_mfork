import tiktoken

# Initialisation de l'encodeur de tokens utilisÃ© par OpenAI
encoder = tiktoken.get_encoding("cl100k_base")

# GÃ©nÃ©ration d'une phrase complexe encapsulant l'univers et le savoir humain
phrase = (
    "Î©âˆ‘Îâ‚€ âˆ‚Î¨(Î»,t) âŠ™ qâ‚(ğ”¿) â†¯ âˆ«Ï€Â² dÏ‡ âˆ´ H(x,t) â‰œ âˆ€â„Œâˆˆâ„â¿, "
    "â†¯ Ïƒâ‚€=âˆ«(ğœ™(âˆ,ğ”µ)âŠ•ğ‘’ğ•)ğ—¿Ï‡Â² âˆ‡Î¨ â†’ â„•Ï‰;"
    "âŠ•â„â‚“ âˆˆğ”¢(â‡˜) : âˆ‚áµ â‚€(ğ”­) â†¦ â„•(áµ ) â‰¡ {Î˜(Î”) âŠ— ğ•†â‚€}; "
    "Î›âˆ â†º ğ•ˆ â‰œ i(Î£(ğ”¿)âŠ™ğ•â‚) âˆ€ğ•Œ(áµ) | ÎÎ©-13Â§âˆ†Î» qâˆ´x(Î©,t) = âˆ«âˆ‚Î¨[Ï†(âˆ)] dÏ‡âŠ™ â†¯ H(A,t) â‰œ âˆ€xâˆˆâ„â¿."
    "â†¦ â„µâˆ… â†’ Î£â‚€â¨€ğ”® â¨ ğ”¸(â„) âˆ‡ ğ•(Î“) âˆ« Î¨(ğ•Š) âŠ— Ï€â‚€ âˆ‡ Î¼â†’ğ”­ ;"
    "âˆ â¨€ Î¨â‚€ âˆ‚Î¦ â†¦ âˆ‘â„•â‚“, âˆ«Î›(â„) â†’ âŠ•â„¤ â†’ â„Œâ‚€ âŠ™ ğ•† âˆ€Î˜."
)

# VÃ©rification du nombre de tokens
tokens = encoder.encode(phrase)
tokens_count = len(tokens)

# Ajustement si nÃ©cessaire
while tokens_count < 521:
    phrase += " âˆ´ Î¨(Î©)"
    tokens = encoder.encode(phrase)
    tokens_count = len(tokens)

while tokens_count > 521:
    phrase = phrase[:-1]  # Suppression de caractÃ¨re pour ajuster
    tokens = encoder.encode(phrase)
    tokens_count = len(tokens)

if __name__ == "__main__":
    print("Liste des tokens:", tokens)
    print("Nombre total de tokens:", tokens_count)
